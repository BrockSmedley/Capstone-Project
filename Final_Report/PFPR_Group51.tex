\documentclass[letterpaper,10pt,serif,draftclsnofoot,onecolumn,compsoc,titlepage]{IEEEtran}

\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{cite}
\usepackage{alltt}
\usepackage{float}
\usepackage{color}
\usepackage[hyphens]{url}
\usepackage{pgfgantt}
\usepackage{rotating}
\usepackage{enumitem}
\usepackage{array}
\usepackage{gensymb}
\usepackage[T1]{fontenc}
\usepackage{balance}
\usepackage[TABBOTCAP, tight]{subfigure}
\usepackage{enumitem}
\usepackage[strict]{changepage}

\usepackage{geometry}
\geometry{margin=.75in}
\usepackage{hyperref}
\usepackage{breakurl}
%\usetikzlibrary{shapes, positioning, calc}
\usepackage{caption}
\usepackage{listings}
\lstset{
  frame=single,
  language=C,
  basicstyle=\small,
}
%\usepackage[utf8]{inputenc}
%pull in the necessary preamble matter for pygments output

\newcommand{\subparagraph}{}
\usepackage{titlesec}
\usepackage{titletoc}
\setcounter{secnumdepth}{5}
\setcounter{tocdepth}{5}
\titleformat{\paragraph} [hang] {\normalfont\normalsize\bfseries} {\theparagraph} {1em} {}

\usepackage{listings}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{
  %frame=tb,
  language=C++, %added
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  %added
  backgroundcolor=\color{black!5}, % set backgroundcolor
  basicstyle=\footnotesize,% basic font setting
  %added
  breaklines=true,
  breakatwhitespace=true,
  tabsize=4
}

%% The following metadata will show up in the PDF properties
\hypersetup{
   colorlinks = true,
   citecolor = black,
   linkcolor = black,
   urlcolor = black,
   breaklinks = true,
   pdfauthor = {Shu-Ping Chien, Brock Smedley, Keith Striby},
   pdfkeywords = {CS463 "Senior Project" Final Report},
   pdftitle = {CS463 Final Report},
   pdfsubject = {CS463 Final Report},
   pdfpagemode = UseNone
}

\parindent = 0.0 in
\parskip = 0.1 in
\title{Final Report: Multi-Camera, SoM Based, Real-Time Video Processing for UAS and VR/AR Applications}
\author{Area 51: Shu-Ping Chien, Brock Smedley, Keith Striby \\ 12 June 2018 \\ CS463, Senior Software Engineering Project, Spring 2018}


\begin{document}
\begin{titlepage}
\maketitle

\begin{abstract}

This document provides insight on our Capstone Senior Project at Oregon State University. 
Over the course of 2017-2018 academic school year, we developed a platform which combines 
live images together using two CSI-based cameras connected to an NVIDIA Jetson TX2 
system-on-module. The video streams are handled by GStreamer a streaming media 
framework, and then using OpenCV we merge the data streams of up to three cameras and 
display the feedback on a live monitor. The software produced outputs a stitched and 
tiled video stream, along with latency estimates. \\

\thispagestyle{empty}
\end{abstract}
\end{titlepage}

\newpage
\tableofcontents

\newpage

\section{Project Introduction}

	\input{Intro_FinalReport}

\newpage

\section{Requirements Document}

	\input{requirements_group51}
\newpage

\subsection{Final Gantt Chart}

	\input{Final_Gantt_Chart}

\newpage

\section{Design Document}

	\input{SDD_Group51}

\newpage

\section{Technology Reviews}

	\subsection{Shu-Ping's Technology Review}

		\input{Shu-Ping_Tech_Review}

	\newpage

	\subsection{Brock Smedley's Technology Review}

		\input{Smedley_Tech_Review}

	\newpage

	\subsection{Keith Striby's Technology Review}

		\input{Striby_Tech_Review}

	\newpage

\section{Weekly Blog Posts}
%each contribute
	\subsection{Shu-Ping Chien's Blog Posts}

		\input{Shu-Ping_Blog}

	\newpage

	\subsection{Brock Smedley's Blog Posts}

		\input{Smedley_Blog}

	\newpage
	
	\subsection{Keith Striby's Blog Posts}

		\input{Striby_Blog}

	\newpage

\section{Final Poster}

	\begin{figure}[H]
		\centering
		\label{fig:ExpoPosterFinal_v2}
		\includegraphics[width=1\textwidth, angle=90]{images/Area51_PosterFinal_v2.eps}
		\caption{Final draft of poster displayed at Expo. \label{overflow}}
	\end{figure}

\newpage

\section{Project Documentation}
%Shu-Ping will do 
\begin{figure}[H]
  \centering
  \label{fig: The product flow diagram.}
  \includegraphics[width=5cm]{images/diagram2.eps}
  \caption{The product flow diagram. \label{overflow}}
\end{figure}

This product was established on the TX2 module, which supported the operating system on Linux and 
connected with three CSI IMX274CS-X cameras from Leopard Imaging through the Connect Tech Inc. 
Spacely Carrier as in the figure. Therefore, there were some required devices used to make the 
system work which were listed in the table below. \\

\begin{tabular}{|p{0.3\linewidth}|p{0.5\linewidth}|}
   \hline
   \textbf{Requirements} & \textbf{Notes} \\ 
   \hline
	Pluggable Terminal Contact & Input Voltage Range: +12V to +22V DC \\
   \hline
   USB 2.0 Hub & Connect to Keyboard and Mouse \\
   \hline
   Micro HDMI Type D to HDMI & Connect to Display Device \\
   \hline
\end{tabular}

The user need to connect the product with power, USB mouse and keyboard, and a display device in 
order to enable all programs created in the application. Once the power was on, the user needed 
to activate the fan and use nvpmodel to change the environment mode to adequate CPU and GPU usage 
setup before executing any programs. \\

Software in the product was accompanied with Jetpack of NVIDIA software development kit is a host 
of open-source programming libraries and APIs to assist our software development.Multiple video 
process programs were created using GStreamer and OpenCV and were available in the finalCode 
directory and could be run with the camke compiler, and the existed functionalities were stitching 
from two cameras, tiling video streaming with two or three cameras, edge detection, and some 
testing cases which display information such as in program latency and framerate in the output 
window. \\

\newpage

The stitching program would stitch two images captured from two cameras by computing the overlapping 
frames in homography and making transformation so it was able to generate one video streaming with 
wider range. The tiling program combined adjusted input frames from two or three different cameras 
and combined frames together horizontally as video output. Although the latency of tiling performed 
better than stitching, the user had to adapt the camera angles physically to acquire side by side 
image. \\

\newpage

\section{Recommended Technical Resources for Learning More}
\subsection{Helpful sites}
\begin{itemize}
	\item elinux.org NVIDIA Jetson TX2 Wiki: \url{https://elinux.org/Jetson_TX2}
	\item JetPack L4T SDK Documentation: \url{https://docs.nvidia.com/jetpack-l4t/index.html}
	\item NVIDIA Virtual Workshops: \url{https://developer.nvidia.com/embedded/learn/tutorials}
	\item GStreamer Documentation: \url{https://gstreamer.freedesktop.org/documentation/}
	\item NVIDIA's Accelerated GStreamer User Guide: \url{http://developer2.download.nvidia.com/embedded/L4T/r27_Release_v1.0/Docs/Jetson_TX2_Accelerated_GStreamer_User_Guide_Release_27.1.pdf?fSyt4imvrsQwLjQGC26vQUGnjIpmNf3Vrk5X6wiq_iq_Si7a8CUcXNWJuUYybsCzRvpyrOn8HnRFun5klMtCdkBc-8jVUWjD4NdnH6zIq68jxY3VKDvV1nkWa1WC6hEak9I1YqkWtmeEiUyhebU47KZi9n-tXr5vpZbhiwLVIaKWEV8bvdLOYG5MQzYkl_WNxL-2zyjDrwFEocDRUgc}
	\item OpenCV Documentation: \url{https://docs.opencv.org/2.4/modules/refman.html}
	\item OpenCV Stitcher docs: \url{https://docs.opencv.org/3.4/d8/d19/tutorial_stitcher.html}
	\item JetsonHacks Blog: \url{https://www.jetsonhacks.com/}
	\item Peter Moran's Blog: \url{http://petermoran.org/csi-cameras-on-tx2/}
\end{itemize}

With so many potential variables involved (OpenCV configuration, GStreamer pipelines, 
cmake configurations, hardware configurations, and other endless variables), 
it's important to be thoughtful and meticulous in your attention to detail. 
Study the official documentation 
deliberately, because one very small overlooked detail can indirectly 
derail a whole build. Also, make sure you understand core concepts -- it's easy to 
overlook minor flaws in forum discussion answers when you don't understand how their 
solution actually works.  \\

\newpage

\section{Conclusions and Reflections}
%each of us have to contribute to this, see the six questions

	\subsection{Shu-Ping Chien's Conclusions and Reflections}

		\input{Shu-Ping_CandR}

	\newpage

	\subsection{Brock Smedley's Conclusions and Reflections}

		\input{Smedley_CandR}

	\newpage
	
	\subsection{Keith Striby's Conclusions and Reflections}

		\input{Striby_CandR}

	\newpage

\section{Appendix 1: Essential Code Listings}
% doesn't have to be everything, but there should be stuff here for someone to learn from
\subsection{GStreamer Pipeline}
The segment code below was the GStreamer pipelines in the program, which allowed three cameras 
to capture videos in specific height and width in thirty frames per second. Once the script was 
executed, videos will be displayed in different windows on the display device. \\

\begin{lstlisting}[
  caption=Three-Camera GStreamer Pipeline,
  label=lst1:mxm,
]
	DISPLAY=:0 gst-launch-1.0 nvcamerasrc sensor-id=0 fpsRange="30 30" ! 
	'video/x-raw(memory:NVMM), width=(int)640, height=(int)480, format=(string)I420, 
	framerate=(fraction)30/1' ! nvegltransform ! nveglglessink  nvcamerasrc sensor-id=2 
	fpsRange="30 30" ! 'video/x-raw(memory:NVMM), width=(int)640, height=(int)480, 
	format=(string)I420, framerate=(fraction)30/1' ! nvegltransform ! nveglglessink 
	nvcamerasrc sensor-id=1 fpsRange="30 30" ! 'video/x-raw(memory:NVMM), width=(int)640, 
	height=(int)480, format=(string)I420, framerate=(fraction)30/1' ! nvegltransform ! 
	nveglglessink -e
\end{lstlisting}

\subsection{Stitching Program}
The stitching program was created with a built-in class in OpenCV, stitcher. The program created 
a stitcher at beginning and set up the mode and if to use GPU, then it stitched two images 
together into single output if stitching successfully. \\

\begin{lstlisting}[
  caption=Partition Code of Stitching,
  label=lst1:mxm,
]
	Ptr<Stitcher> test = Stitcher::create(mode, try_use_gpu);
    Stitcher::Status status = test->stitch(imgs, pano);
  
    if (status != Stitcher::OK)
    {
        cout << "Error stitching - Code: " <<int(status)<<endl;
        return -1;
    }
\end{lstlisting}

\newpage
\subsection{Tiling Program}
The tiling program below worked to combined three size-adjusted images together horizontally, 
so there would be one video output sent to the display device. \\

\begin{lstlisting}[
  caption=Partition Code of Tiling with Three Cameras,
  label=lst1:mxm,
]
	fr1 = fr1(Range(0, fr1.rows), Range(fr1.cols/5-1, 2*fr1.cols/5-1));
	fr2 = fr2(Range(0, fr2.rows), Range(fr2.cols/5-1, 2*fr2.cols/5-1));
	fr3 = fr3(Range(0, fr3.rows), Range(fr3.cols/5-1, 2*fr3.cols/5-1));
	//apply horizontal concatenation on inputs/matrices
	hconcat(fr1, fr2, tile);        	
	hconcat(tile, fr3, out);
    imshow("Tiled Image", out);
\end{lstlisting}

\subsection{Edge Detection Program}
In the edge detection program, a frame was translated into grayscale in order to be applied 
on Canny edge detection function. Then the processed output generated an image in black 
background and the white framework of objects. \\

\begin{lstlisting}[
  caption=Partition Code of Edge Detection,
  label=lst1:mxm,
]
	cvtColor(frame2, gray, CV_BGR2GRAY);
	GaussianBlur(gray, gray, Size(3 ,3 ), 0, 0);
	Canny(gray, dst1, 50, 150, 3);
		
	imshow("Display1", frame1);
	imshow("Edge Detection", dst1);
\end{lstlisting}

\nocite{*}
\newpage
\bibliographystyle{ieeetr}
\bibliography{PFPR_Group51}
\end{document}