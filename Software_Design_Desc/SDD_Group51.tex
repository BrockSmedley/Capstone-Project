\documentclass[letterpaper,10pt,serif,draftclsnofoot,onecolumn,compsoc,titlepage]{IEEEtran}

\usepackage{graphicx}                                        
\usepackage{amssymb}                                         
\usepackage{amsmath}                                         
\usepackage{amsthm}                                          
\usepackage{cite}
\usepackage{alltt}                                           
\usepackage{float}
\usepackage{color}
\usepackage[hyphens]{url}
\usepackage{pgfgantt}
\usepackage{rotating}
\usepackage{enumitem}
\usepackage{gensymb}
\usepackage[T1]{fontenc}

\usepackage{balance}
\usepackage[TABBOTCAP, tight]{subfigure}
\usepackage{enumitem}

\usepackage{geometry}
\geometry{margin=.75in}
\usepackage{hyperref}
\usepackage{breakurl}
%\usetikzlibrary{shapes, positioning, calc}
\usepackage{caption}
\usepackage{listings}
%\usepackage[utf8]{inputenc}
%pull in the necessary preamble matter for pygments output

%% The following metadata will show up in the PDF properties
\hypersetup{
   colorlinks = true,
   citecolor = black,
   linkcolor = black,
   urlcolor = black,
   breaklinks = true,
   pdfauthor = {Shu-Ping Chien, Brock Smedley, W Keith Striby Jr},
   pdfkeywords = {CS461 "Senior Project" Software Design Description},
   pdftitle = {CS461 Software Design Description},
   pdfsubject = {CS461 Software Design Description},
   pdfpagemode = UseNone
}

\parindent = 0.0 in
\parskip = 0.1 in
\title{Software Design Description: Multi-Camera, SoM Based, Real-Time Video Processing for UAS and VR/AR Applications}
\author{Area 51: Shu-Ping Chien, Brock Smedley, W Keith Stirby Jr \\ 01 December 2017 \\ CS461, Senior Software Engineering Project, Fall 2017}
\begin{document}
\begin{titlepage}
\maketitle
\begin{abstract}

abstract words \\

\thispagestyle{empty}
\end{abstract}
\end{titlepage}

%\newpage
%\tableofcontents

\newpage

\section{Frontispiece}

\subsection{Date of issue and status}

01 December 2017, In-progress \\

\subsection{Issuing Organization}

Rockwell Collins, CS Capstone Group 51, Oregon State University \\

\subsection{Authorship}

Shu-Ping Chien, Brock Smedley, W Keith Stirby Jr \\

\section{Introduction}

\subsection{Purpose}

This document is a general description of design concepts that will be used for our 
multi-camera, SoM based, real-time video processing for UAS and VR/AR applications. 
It is a reference to guide the development of our product.  \\

\subsection{Scope}

Our product will receive input from multiple cameras and then provide a video output at 
near real-time. Our software will receive the pixel data from the cameras and format 
the pixel streams so that image processing can occur. Image processing will then stitch 
the multiple streams of pixels being received to create a combined output. The software 
will be flashed onto the NVIDIA TX1/2, which receives input from the carrier 
board that is connected to the cameras. \\

\subsection{Overview}

The development and design of our product requires: hardware interface and system 
architecture, receiving camera input and formatting for image processing, and image 
processing for video output. The structure of our document reflects these three areas 
of our software required for our product. \\ 

\newpage
\section{References}

\bibliographystyle{ieeetr}
\bibliography{SDD_Group51}

\subsection{Definitions, Acronyms, Abbreviations}

\subsubsection{Definitions}

\begin{tabular}{|l|p{11cm}|}
	\hline
	\textbf{Term} & \textbf{Definition}\\
	low visibility & Inability to see clearly with the naked eye.\\
	\hline	
	multiple cameras & At least two cameras, but a maximum of six cameras for 
	video input.\\
	\hline
	near real-time & Fast enough that a human could not notice the time 
	delay (lag) between \newline real life images and images displayed by the system.\\
	\hline
	NVIDIA TX1/2 & NVIDIA GPUs, the Jetson TX1 or the Jetson TX2.\\
	\hline
	spectral bands & Electromagnetic frequency ranges; different 
	spectrums of light, including \newline but not limited to infrared 
	and visible light.\\
	\hline
	standalone & The system performs its functionality independent of another
	system, in our product's case it will be independent of a development kit. \\
	\hline
	stitched (video) output & a composite image formed from multiple images\\
	\hline
	time division multiplexing & The illusion of simultaneous execution in a CPU due
	to a CPU being capable of running one process at a time.\\
	\hline
\end{tabular}

\subsubsection{Acronyms}

\begin{tabular}{|l|l|}
	\hline
	\textbf{Acronym} & \textbf{Term}\\
	\hline
	CPU & Central Processing Unit\\
	\hline
	CSI & Camera Serial Interface\\
	\hline
	EVS & Enhanced Vision System\\
	\hline
	fps & Frames per second\\
	\hline
	GPS & Global Positioning System\\
	\hline
	GPU & Graphic Processing Unit\\
	\hline
	ISP & Image Signal Processors\\
	\hline
	IMU & Inertial Measurement Unit\\
	\hline
	HUD & Head-up Display\\
	\hline
	SoC & System-on-chip\\
	\hline
	SoM & System-on-module\\
	\hline
	SWaP-C & Size, weight, power and cost\\
	\hline
	VI & Video Input\\
	\hline
\end{tabular}

\newpage
\section{System Overview}  

\subsection{Identified Stakeholders and Design Concerns}

Rockwell Collins is the primary customer of this product. The company provides 
engineering products in the aviation industry for commercial and military customers. 
Rockwell Collins is the primary user of the product and it is contributing 
to the development of a system that will be used in UAS and VR/AR applications. \\

\subsection{Hardware Context}

The hardware used in our product will be the NVIDIA Jetson TX1/2 as our SoM, 
a carrier board, and cameras. The input from cameras will be transferred through 
carrier boards, and the TX1/2 will format and process the input to produce a 
video output. The software we're developing will be on the TX1/2. \\

\subsection{Software Context}

The software pieces in this project include: GStreamer for transforming video input 
from CSI for image processing, and OpenGL development environment for image processing 
to produce the video output. The pipeline feature in GStreamer will reduce 
cost on time and storage to help achieve near real-time image processing. The OpenGL 
will stitch input images from GStreamer and print the output to the display device. \\

\section{System Architecture}

\subsection{Interfaces}
The NVIDIA TX2 is an SoM with an ARM processor and an NVIDIA GPU. It includes several interfaces that can be used to exchange data with the module such as Ethernet, USB, I2C, and GPIO, among others. These connect to the TX2 via a 400-pin connector that attaches to a carrier board, which has a set of ports to interface with. These interfaces will be used in our implementation of the project for varying purposes.

\subsubsection{Ethernet}
Ethernet is essential for development. It will allow us to connect to the internet and will also allow us to control the system remotely using SSH. Ethernet will likely not be used in the final implementation, however. The final implementation will likely have an image flashed directly to its memory so that there is no need to download any new software or data. The carrier board we will be using in the final implementation may not have an Ethernet connection, but if it does not have it, we can attach the TX2 to the dev board that it came with, which has at least one connection for every interface that the TX2 supports.

\subsubsection{USB}
USB will be necessary for flashing the TX2 with a new image. This only needs to be done once at the start of development, and possibly again when a production image is ready to be flashed, but it is nonetheless required for development. USB can also be used for simple file transfers in cases where the internet is not available. USB will also not be present on the final product, but it should not be necessary at that stage; we will not be using USB for any system-critical functions. The TX2 can always be plugged into the dev board if changes to the system need to be made, and then re-attached to the final-product board with the new data on it.

\subsubsection{I2C \& GPIO}
I2C (The Inter-integrated Circuit) and GPIO (General-purpose Input/Output) will be used in later phases of the project which we may not actually work on. These interfaces can be used for connecting things like environmental sensors and control interfaces like buttons and knobs. Our portion of the project will focus solely on creating the camera system on the TX2 which can then be expanded upon by other teams.

\subsection{Architecture}
\subsubsection{Operating Systems}
The TX2 supports ARM Linux 4 operating systems, and the OS we’ll be using for this project is Linux4Tegra (L4T). L4T is an ubuntu variant that comes preloaded with a bundle of software that can be used to take advantage of the processing power that the TX2 has to offer. L4T is simply an Ubuntu ARM image with NVIDIA drivers pre-installed. Using L4T takes the guesswork out of developing the software environment so that more time can be spent developing the core solution.

\subsubsection{Deployment Software}
L4T will be flashed onto the TX2 system memory using NVIDIA Jetpack. Jetpack allows us to choose the operating system and software to be installed on the TX2. It runs on a separate Ubuntu host which is connected to the TX2 via USB and a router connecting both the machines to the internet, and can be downloaded from the NVIDIA’s website after creating an account. Ubuntu is not required to run Jetpack, but NVIDIA strongly recommends it, and Ubuntu is a very user-friendly and robust operating system, so it will suit our development needs perfectly.

\subsubsection{Development}
Once L4T is flashed to the TX2 from Jetpack, we can use the TX2 like a normal computer, using USB to connect a mouse \& keyboard, and HDMI to connect a monitor. Development can occur directly on the TX2 or remotely via SSH (Ethernet). We will likely use a combination of the two; sometimes it is required, for example when internet access is not available; sometimes it’s just more convenient.
\\
We will also make use of a GitHub repository to keep our code, which can be accessed by the TX2 via the internet. This will allow each group member to work on different parts of the project simultaneously without interfering with other group members’ work. Most Linux variants come with a version of Git, but if L4T does not, then we can always install it using Ubuntu’s package manager.

\subsubsection{subsection topic of topic to design}

words \\

\subsubsection{another subsection topic of topic to design}

words \\


\nocite{*}
%\newpage
%\bibliographystyle{ieeetr}
%\bibliography{SDD_Group51}
\end{document}